---

title: Base Model

keywords: fastai
sidebar: home_sidebar

summary: "This class contains the base which is used to train data upon."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Model" class="doc_header"><code>class</code> <code>Model</code><a href="https://github.com/sachinruk/profetorch/tree/master/profetorch/model/model.py#L22" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Model</code>(<strong><code>df</code></strong>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>model_args</code></strong>=<em><code>None</code></em>, <strong><code>quantiles</code></strong>=<em><code>[0.05, 0.5, 0.95]</code></em>, <strong><code>loss</code></strong>=<em><code>None</code></em>, <strong><code>bs</code></strong>=<em><code>128</code></em>, <strong><code>epochs</code></strong>=<em><code>100</code></em>, <strong><code>lr</code></strong>=<em><code>0.3</code></em>, <strong><code>alpha</code></strong>=<em><code>0</code></em>, <strong><code>beta</code></strong>=<em><code>0.1</code></em>, <strong><code>silent</code></strong>=<em><code>True</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Default Model Wrapper
parameters:</p>
<ul>
<li>df: dataset used in training dataset.</li>
<li>model (optional): how to model time series. Default: DefaultModel.</li>
<li>loss (optional): loss function: Default l1 loss.</li>
<li>bs (optional): batchsize</li>
<li>alpha (optional): l2 weight decay</li>
<li>beta (optional): l1 weight decay</li>
<li>silent: whether to silence output or not</li>
</ul>
<p>Usage:</p>

<pre><code>model = Model(train_df)
model.fit(train_df)
y = model.predict(test_df)</code></pre>

</div>

</div>

</div>
</div>

</div>
</div>
 

